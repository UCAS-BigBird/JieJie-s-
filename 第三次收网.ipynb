{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从这里开始\n",
    "#这里两个部分都是一样的 从同一张表格出发\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "all_data=pd.read_csv('D:/new_date.csv',low_memory=False)\n",
    "print(all_data.shape)\n",
    "\n",
    "#这里把数据集打乱 防止人都出现在一起\n",
    "all_data = all_data.sample(frac=1.0)\n",
    "all_data = all_data.reset_index()\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "print(missing_data.head)\n",
    "\n",
    "\n",
    "#删除一个样本 也许会漏掉一个user_id 这里我的态度很坚决 漏就漏了 我赋值0.5\n",
    "#因为假数据也是猜 为什么不猜一手大的？\n",
    "all_data.drop(all_data[all_data['customer_province']=='柔佛'].index,inplace=True)\n",
    "print(all_data.shape)\n",
    "\n",
    "\n",
    "all_data['is_customer_rate'].fillna(0,inplace=True)\n",
    "all_data['customer_gender'].fillna(0,inplace=True)\n",
    "all_data['is_member_actived'].fillna(0,inplace=True)\n",
    "\n",
    "#member_status 有点奇怪 只有1  所以填充的时候要附上一个2 \n",
    "#all_data['member_status'].plot()\n",
    "#子订单应付总金额不能填充0 请注意 实在是太多了所以删除掉\n",
    "\n",
    "all_data['member_status'].fillna(2,inplace=True)\n",
    "all_data.drop(columns=['order_detail_amount'],inplace=True)\n",
    "all_data.drop(columns=['customer_city','customer_province'],inplace=True)\n",
    "#把一些莫名其妙的drop\n",
    "all_data.drop(columns=['level_0','Unnamed: 0'],inplace=True)\n",
    "\n",
    "'''\n",
    "#这个地方排序一下 后面就写的更舒服一些一定要注意 这里不排序 后面减就会有副职\n",
    "#当然也可以在排序的时候再写\n",
    "all_data.sort_values(by='order_pay_time',inplace=True)\n",
    "'''\n",
    "\n",
    "#下面查看缺失量\n",
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
    "missing_data.head\n",
    "\n",
    "#日期处理\n",
    "all_data['order_pay_time'] = pd.to_datetime(all_data['order_pay_time'])\n",
    "all_data['order_pay_date'] = all_data['order_pay_time'].dt.date\n",
    "##地区编码\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "all_data['new_location_code'] = label.fit_transform(all_data['new_location'])\n",
    "print(\"日期处理完毕-地区编码也已经完成\")\n",
    "#这个时候先导入训练好的物品特征 \n",
    "#通过制定聚类算法 已经打好了20种标签\n",
    "#这里先不急着把他马上拼接上去\n",
    "#而是要给每一个客人买过的id先打上标签让每一行都有商品的特征\n",
    "goods_feature=pd.read_csv('goods_feature.csv')\n",
    "goods_feature.drop(columns='Unnamed: 0',inplace=True)\n",
    "print(\"商品特征读取成功\")\n",
    "\n",
    "\n",
    "\n",
    "all_data=pd.merge(all_data,goods_feature[['goods_id','Goods_clustering_kind']],on='goods_id')\n",
    "print(all_data.shape)\n",
    "print('所有的前期处理准备完毕')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#下面要对商品种类开始处理\n",
    "#请注意脑袋不要乱  这个地方不要乱merge\n",
    "#因为我需要的是每一种类的值\n",
    "#其实按道理来说 这个处理应该要在商品种处理好,而不是放在这个地方处理\n",
    "\n",
    "#商品种类平均价格\n",
    "Goods_kind__price_mean=goods_feature.groupby('Goods_clustering_kind')['goods_price_mean'].agg({'Goods_kind__price_mean':np.mean})\n",
    "print(Goods_kind__price_mean,'\\n')\n",
    "\n",
    "#商品种类的会员折扣\n",
    "Goods_kind_member_discount_mean=goods_feature.groupby('Goods_clustering_kind')['goods_memeber_discount'].agg({'Goods_member_discount_mean':np.mean})\n",
    "print(Goods_kind_member_discount_mean,'\\n')\n",
    "\n",
    "#商品种类的在库状态\n",
    "Goods_kind_status_mean=goods_feature.groupby('Goods_clustering_kind')['goods_status_mean'].agg({'Goods_kind_status_mean':np.mean})\n",
    "print(Goods_kind_status_mean,'\\n')\n",
    "\n",
    "#商品种类的平均在架时间\n",
    "Goods_kind_date_time_mean=goods_feature.groupby('Goods_clustering_kind')['deta_time_mean'].agg({'Goods_kind_date_time_mean':np.mean})\n",
    "print(Goods_kind_date_time_mean,'\\n')\n",
    "\n",
    "#商品种类的最大优惠了多少\n",
    "Goods_kind_discount=goods_feature.groupby('Goods_clustering_kind')['goods_discount'].agg({'Goods_kind_discount':np.mean})\n",
    "print(Goods_kind_discount,'\\n')\n",
    "\n",
    "#商品种类的性别\n",
    "Goods_kind_gender=goods_feature.groupby('Goods_clustering_kind')['goods_gender'].agg({'Goods_kind_gender':np.mean})\n",
    "\n",
    "print(Goods_kind_gender,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def merge1(df):\n",
    "    all_user=df\n",
    "    for i in range(20):\n",
    "        all_user['商品种类'+str(i)+'平均价格']=all_user['已经购买的商品种类—'+str(i)].apply(\n",
    "                                                                        lambda x:Goods_kind__price_mean.values.flatten()[i] if x==1 else 0)\n",
    "        all_user['商品种类'+str(i)+'的会员折扣']=all_user['已经购买的商品种类—'+str(i)].apply(\n",
    "                                                                        lambda x:Goods_kind_member_discount_mean.values.flatten()[i] if x==1 else 0)\n",
    "        all_user['商品种类'+str(i)+'的在库状态']=all_user['已经购买的商品种类—'+str(i)].apply(\n",
    "                                                                        lambda x:Goods_kind_status_mean.values.flatten()[i] if x==1 else 0)\n",
    "        all_user['商品种类'+str(i)+'的平均在架时间']=all_user['已经购买的商品种类—'+str(i)].apply(\n",
    "                                                                        lambda x:Goods_kind_date_time_mean.values.flatten()[i] if x==1 else 0)\n",
    "        all_user['商品种类'+str(i)+'的最大优惠了多少']=all_user['已经购买的商品种类—'+str(i)].apply(\n",
    "                                                                        lambda x:Goods_kind_discount.values.flatten()[i] if x==1 else 0)\n",
    "        all_user['商品种类'+str(i)+'的性别']=all_user['已经购买的商品种类—'+str(i)].apply(\n",
    "                                                                        lambda x:Goods_kind_gender.values.flatten()[i] if x==1 else 0)\n",
    "    return all_user\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_feature_and_label(date1,date2,isSubmit):\n",
    "    \n",
    "    # #下面开始聚合用户特征 这个函数一举两得\n",
    "    #为什么？因为每一个用户只能出现一次\n",
    "    #而且通过这个特征还得到了客户的购买次数，写的很漂亮！\n",
    "    # 统计这个用户出现了多少次\n",
    "    date1['count'] = 1\n",
    "    customer_id = date1.groupby(['customer_id'],as_index=False)['count'].agg({'count':'count'})\n",
    "    \n",
    "   \n",
    "    #第一步开始聚合商品\n",
    "    date1['购买了商品+'] = list(map(lambda x: '已经购买的商品种类—' + str(x),date1.Goods_clustering_kind))\n",
    "    temp = pd.crosstab(date1['customer_id'],date1['购买了商品+']).reset_index()\n",
    "    #要注意 两条线\n",
    "    #一条主线是output\n",
    "    #另一条主线是不能动的data1 当然也有data2\n",
    "    #然后\n",
    "    output=pd.merge(customer_id,temp,on='customer_id')\n",
    "    output=merge1(output)\n",
    "    print('已经把购买商品的属性加上去了')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #1\n",
    "    q=date1['order_pay_time'].apply(lambda x: x.month)\n",
    "    date1['购买了商品+'] = list(map(lambda x:str(x)+'月份购买',q))\n",
    "    temp = pd.crosstab(date1['customer_id'],date1['购买了商品+']).reset_index()\n",
    "    del date1['购买了商品+']\n",
    "    output = pd.merge(output, temp, on=['customer_id'], how='left')  #\n",
    "    print(\"把月份属性加上了\")\n",
    "    \n",
    "    #如果是训练集的话是需要管的\n",
    "    #如果是全集的话是不用管的\n",
    "    if isSubmit ==False:\n",
    "        output['8月份购买']=0\n",
    "        output['9月份购买']=0\n",
    "        output['10月份购买']=0\n",
    "        output['11月份购买']=0\n",
    "        output['12月份购买']=0\n",
    "    \n",
    "    q=date1['order_pay_time'].apply(lambda x: x.day)\n",
    "    date1['购买了商品+'] = list(map(lambda x:str(x)+'天购买',q))\n",
    "    temp = pd.crosstab(date1['customer_id'],date1['购买了商品+']).reset_index()\n",
    "    del date1['购买了商品+']\n",
    "    output = pd.merge(output, temp, on=['customer_id'], how='left')  #\n",
    "    print('把天的属性加上了')\n",
    "\n",
    "    # 2,用户各个每月购买量占比（总的）\n",
    "    for i in range(1,8):\n",
    "        output['Month_'+str(i)+'_rate'] = output[str(i)+'月份购买'] / output['count']\n",
    "    # 3,用户各天购买率占比（总的）\n",
    "    for i in range(1,32):\n",
    "        output['day_'+str(i)+'_rate']= output[str(i)+'天购买'] / output['count']\n",
    "    \n",
    "    #result['day_30_rate'] = result['31天购买'] / result['count']\n",
    "\n",
    "    print(\"此时输出已经加上每天的以及每个月的购买率\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #用户总购买的商品数目五个属性\n",
    "    customer_buy_goods_num = date1.groupby(['customer_id'], as_index=False)['order_total_num'].agg(\n",
    "                                                                                  {  'order_total_num_max':'max',\n",
    "                                                                                     'order_total_num_mean':'mean',\n",
    "                                                                                     'order_total_num_min':'min',\n",
    "                                                                                     'order_total_num_sum':'sum',\n",
    "                                                                                     'order_total_num_median':'median'}\n",
    "                                                                                                  )\n",
    "    print('用户总购买的商品数目五个属性输出ok')\n",
    "    #父订单商品总金额五个属性\n",
    "    customer_total_pay = date1.groupby(['customer_id'], as_index=False)['order_amount'].agg(\n",
    "                                                                                    {'order_amount_max':'max',\n",
    "                                                                                     'order_amount_mean':'mean',\n",
    "                                                                                     'order_amount_min':'min',\n",
    "                                                                                     'order_amount_sum':'sum',\n",
    "                                                                                     'order_amount_median':'median'})\n",
    "    \n",
    "    print('父订单商品总金额五个属性ok')\n",
    "    #父订单实付金额\n",
    "    customer_real_pay = date1.groupby(['customer_id'], as_index=False)['order_total_payment'].agg(\n",
    "                                                                                    {'order_total_payment_max':'max',\n",
    "                                                                                     'order_total_payment_mean':'mean',\n",
    "                                                                                     'order_total_payment_min':'min',\n",
    "                                                                                     'order_total_payment_sum':'sum',\n",
    "                                                                                     'order_total_payment_median':'median'})\n",
    "    print('父订单实付金额ok')\n",
    "    #父订单优惠金额\n",
    "    customer_happy_pay = date1.groupby(['customer_id'], as_index=False)['order_total_discount'].agg(\n",
    "                                                                                    {'order_total_discount_max':'max',\n",
    "                                                                                     'order_total_discount_mean':'mean',\n",
    "                                                                                     'order_total_discount_min':'min',\n",
    "                                                                                     'order_total_discount_sum':'sum',\n",
    "                                                                                     'order_total_discount_median':'median'})\n",
    "    print('父订单优惠金额ok')\n",
    "    #父订单包含的子订单数量的五个属性\n",
    "    customer_number = date1.groupby(['customer_id'], as_index=False)['order_count'].agg(\n",
    "                                                                                    {'order_count_max':'max',\n",
    "                                                                                     'order_count_mean':'mean',\n",
    "                                                                                     'order_count_min':'min',\n",
    "                                                                                     'order_count_sum':'sum',\n",
    "                                                                                     'order_count_median':'median'})\n",
    "    print('父订单包含的子订单数量的五个属性ok')\n",
    "    #子订单实付金额\n",
    "    customer_son_real_pay = date1.groupby(['customer_id'], as_index=False)['order_detail_payment'].agg(\n",
    "                                                                                    {'order_detail_payment_max':'max',\n",
    "                                                                                     'order_detail_payment_mean':'mean',\n",
    "                                                                                     'order_detail_payment_min':'min',\n",
    "                                                                                     'order_detail_payment_sum':'sum',\n",
    "                                                                                     'order_detail_payment_median':'median'})\n",
    "    print('子订单实付金额ok')\n",
    "    #子订单优惠金额\n",
    "    customer_son_happy_pay = date1.groupby(['customer_id'], as_index=False)['order_detail_discount'].agg(\n",
    "                                                                                    {'order_detail_discount_max':'max',\n",
    "                                                                                     'order_detail_discount_mean':'mean',\n",
    "                                                                                     'order_detail_discount_min':'min',\n",
    "                                                                                     'order_detail_discount_sum':'sum',\n",
    "                                                                                     'order_detail_discount_median':'median'})\n",
    "    print('子订单优惠金额ok')\n",
    "    \n",
    "    \n",
    "    output=pd.merge(output,customer_buy_goods_num,on='customer_id')\n",
    "    output=pd.merge(output,customer_total_pay,on='customer_id')\n",
    "    output=pd.merge(output,customer_real_pay,on='customer_id')\n",
    "    output=pd.merge(output,customer_happy_pay,on='customer_id')\n",
    "    output=pd.merge(output,customer_number,on='customer_id')\n",
    "    output=pd.merge(output,customer_son_real_pay,on='customer_id')\n",
    "    output=pd.merge(output,customer_son_happy_pay,on='customer_id')\n",
    "    print(\"现在人的特征我把你merge上了\")\n",
    "    \n",
    "    # 统计这个用户的订单最后一次购买时间\n",
    "    last_time = date1.groupby(['customer_id'],as_index=False)['order_pay_date'].agg({'order_pay_date_last':'max',\n",
    "                                                                                     'order_pay_date_first':'min'}\n",
    "                                                                                    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    #购买时间间隔 这个地方不要提取错了\n",
    "    date1.sort_values(by='order_pay_time',inplace=True)\n",
    "    q=date1.groupby(['customer_id'], as_index=False)['order_pay_time'].agg({'deta_time_mean':(lambda x:x.diff().mean()),\n",
    "                                                                           'deta_time_max':(lambda x:x.diff().max()),\n",
    "                                                                           'deta_time_min':(lambda x:x.diff().min())\n",
    "                                                                          })\n",
    "    #要是中间就买了一次 我们认为时间间隔为0\n",
    "    q.fillna(0,inplace=True)\n",
    "    q['deta_time_mean']=q['deta_time_mean'].dt.days\n",
    "    q['deta_time_max']=q['deta_time_max'].dt.days\n",
    "    q['deta_time_min']=q['deta_time_min'].dt.days\n",
    "    \n",
    "    output=pd.merge(output,last_time,on='customer_id')\n",
    "    output=pd.merge(output,q,on='customer_id')\n",
    "    print('时间也已经把你拼接上去了')\n",
    "    \n",
    "    \n",
    "    #return output\n",
    "    print('下面开始地域特征拼接')\n",
    "    Location=date1.groupby(['customer_id','new_location_code'])['new_location_code'].agg({'最多来自哪里':np.size})\n",
    "    Location=Location.reset_index().sort_values(by='最多来自哪里',ascending=False)\n",
    "    Location=Location.drop_duplicates('customer_id')\n",
    "    Location=Location[['customer_id','最多来自哪里']]\n",
    "    \n",
    "    print('下面获取经纬度数据')\n",
    "    \n",
    "    Longtitude = date1.groupby(['customer_id'], as_index=False)['精度'].agg(\n",
    "                                                                              {  '精度_max':'max',\n",
    "                                                                                 '精度_mean':'mean',\n",
    "                                                                                 '精度_min':'min',\n",
    "                                                                                 '精度_median':'median'}\n",
    "                                                                                              )\n",
    "\n",
    "    Latitude = date1.groupby(['customer_id'], as_index=False)['纬度'].agg(\n",
    "                                                                              {  '纬度_max':'max',\n",
    "                                                                                 '纬度_mean':'mean',\n",
    "                                                                                 '纬度_min':'min',\n",
    "                                                                                 '纬度_median':'median'}\n",
    "                                                                                              )\n",
    "    print('经纬度数据完毕')\n",
    "    \n",
    "   \n",
    "    output=pd.merge(output,Location,on='customer_id')\n",
    "    output=pd.merge(output,Longtitude,on='customer_id')\n",
    "    output=pd.merge(output,Latitude,on='customer_id')\n",
    "    \n",
    "    print(\"至此 全部的数据拼接完毕\")\n",
    "\n",
    "    print(\"进入提交环节\")\n",
    "\n",
    "    if isSubmit==False:\n",
    "        print(\"您选择的是本地训练模式\")\n",
    "        output['order_pay_date_jiange']=(output['order_pay_date_last']-output['order_pay_date_first']).dt.days\n",
    "        output['label'] = 0\n",
    "        output.loc[output['customer_id'].isin(list(date2['customer_id'].unique())),'label'] = 1\n",
    "        output=output.drop(columns=['order_pay_date_last','order_pay_date_first'])\n",
    "    else:\n",
    "        print('您选择的是合并所有集合模式')\n",
    "        output['order_pay_date_jiange'] = pd.to_datetime('2013-12-31') - pd.to_datetime(output['order_pay_date_last'])\n",
    "        output['order_pay_date_jiange'] = output['order_pay_date_jiange'].dt.days + 1\n",
    "        output=output.drop(columns=['order_pay_date_last','order_pay_date_first'])\n",
    "    \n",
    "    print(\"合并完成，现在开始输出\")\n",
    "    print(output.shape)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#划分训练集和全部集合\n",
    "# 生成训练数据和提交数据\n",
    "train_history = all_data[(all_data['order_pay_date'].astype(str)<='2013-11-12')]\n",
    "online_history = all_data[(all_data['order_pay_date'].astype(str)<='2013-12-31')]\n",
    "train_label = all_data[all_data['order_pay_date'].astype(str)>='2013-07-04']\n",
    "\n",
    "\n",
    "train = make_feature_and_label(train_history,train_label,False)\n",
    "#submit = make_feature_and_label(online_history,None,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('my_train_change_big.csv')\n",
    "print(\"文件生成完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = make_feature_and_label(online_history,None,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit 是my_all_change\n",
    "submit.to_csv('my_all_change.csv')\n",
    "train.to_csv('my_train_change.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output=pd.read_csv('my_train.csv')\n",
    "#print(output.shape)\n",
    "#print(output.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "def logloss(y_true, y_pred,deta = 3.4, eps=1e-15):\n",
    "    # Prepare numpy array data\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    assert (len(y_true) and len(y_true) == len(y_pred))\n",
    "    # Clip y_pred between eps and 1-eps\n",
    "    p = np.clip(y_pred, eps, 1-eps)\n",
    "    loss = np.sum(- y_true * np.log(p) * deta - (1 - y_true) * np.log(1-p))\n",
    "    return loss / len(y_true)\n",
    "\n",
    "\n",
    "\n",
    "param = {\n",
    "    'num_leaves':128,\n",
    "    'objective':'binary',\n",
    "    'max_depth':-1,\n",
    "    'learning_rate':0.1,\n",
    "    'metric':'binary_logloss',\n",
    "    'bagging_fraction':0.95,\n",
    "    'bagging_freq':5,\n",
    "    \"device_type \":'gpu',\n",
    "    'gpu_use_dp':True,\n",
    "    \"scale_pos_weight\":5\n",
    "\n",
    "}\n",
    "# 构建机器学习所需的label和data\n",
    "\n",
    "\n",
    "\n",
    "feature = [x for x in train.columns if x not in ['customer_id']]\n",
    "print(\"最终提取的特征是：\",feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train[feature]\n",
    "# 划分训练集和验证集\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_loss(y_pred, data_vail):\n",
    "    \n",
    "    deta = 3.4\n",
    "    eps=1e-15\n",
    "    \n",
    "    labels = data_vail.get_label()\n",
    "    p = np.clip(y_pred, eps, 1-eps)\n",
    "    loss = np.sum(- labels * np.log(p) * deta - (1 - labels) * np.log(1-p))\n",
    "    return 'log_loss', loss/ len(labels), False\n",
    "\n",
    "\n",
    "param = {\n",
    "    'num_leaves':128,\n",
    "    'objective':'binary',\n",
    "    'max_depth':-1,\n",
    "    'learning_rate':0.1,\n",
    "    #'metric':'binary_logloss',\n",
    "    'bagging_fraction':0.95,\n",
    "    'bagging_freq':5,\n",
    "    \"device_type \":'gpu',\n",
    "    'gpu_use_dp':True,\n",
    "    \"scale_pos_weight\":5\n",
    "\n",
    "}\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n",
    "\n",
    "\n",
    "#\n",
    "trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "lgbm = lgb.train(param,\n",
    "                 trn_data,\n",
    "                 valid_sets=[trn_data,val_data],\n",
    "                 num_boost_round = 100 ,\n",
    "                 #early_stopping_rounds=1000,\n",
    "                 learning_rates=lambda iter: 0.05 * (0.99 ** iter),\n",
    "                 feval=log_loss\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logloss(y_true, y_pred,deta = 3.4, eps=1e-15):\n",
    "    # Prepare numpy array data\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    assert (len(y_true) and len(y_true) == len(y_pred))\n",
    "    # Clip y_pred between eps and 1-eps\n",
    "    p = np.clip(y_pred, eps, 1-eps)\n",
    "    loss = np.sum(- y_true * np.log(p) * deta - (1 - y_true) * np.log(1-p))\n",
    "    return loss / len(y_true)\n",
    "\n",
    "\n",
    "y_pred1 = lgbm.predict(X_valid,num_iteration=lgbm.best_iteration)\n",
    "error1 = logloss(y_valid,y_pred1)\n",
    "print('验证集上的误差为：',error1)\n",
    "\n",
    "y_pred2 = lgbm.predict(X_train,num_iteration=lgbm.best_iteration)\n",
    "error2 = logloss(y_train,y_pred2)\n",
    "#mse2.append(error2)\n",
    "print('训练集上的误差为：',error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submit_df = submit[['customer_id']]\n",
    "X_submit = submit[feature]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_submit=X_submit[0:200000]\n",
    "y1_submit = lgbm.predict(q_submit)\n",
    "del q_submit\n",
    "q_submit=X_submit[200000:300000]\n",
    "y2_submit = lgbm.predict(q_submit)\n",
    "del q_submit\n",
    "q_submit=X_submit[400000:600000]\n",
    "y2_submit = lgbm.predict(q_submit)\n",
    "del q_submit\n",
    "q_submit=X_submit[600000:929806]\n",
    "y3_submit = lgbm.predict(q_submit)\n",
    "del q_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_submit=X_submit[200000:300000]\n",
    "y2_submit = lgbm.predict(q_submit)\n",
    "del q_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = lgbm.predict(q_submit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_customer = pd.merge(all_customer,submit_df,on=['customer_id'],how='left',copy=False)\n",
    "all_customer = all_customer.sort_values(['customer_id'])\n",
    "all_customer['customer_id'] = all_customer['customer_id'].astype('int64')\n",
    "all_customer['result'] = all_customer['result'].fillna(0)\n",
    "all_customer.to_csv('./mpdf_baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submit_df = submit[['customer_id']]\n",
    "X_submit = submit[feature]\n",
    "y_submit = lgbm.predict(X_submit)\n",
    "\n",
    "submit_df['result'] = y_submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
